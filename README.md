# LLMS_WWSI
1. Run Inference of Qwen3-0.6B using Colab or MLX (mac users).
2. Train a 10M params llama model on 0.5M-1B tokens (BabyLlama notebook)
3. Supervised finetune Qwen2.5-0.5B Base using QLoRA (Notebook)
